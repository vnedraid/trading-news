import feedparser
from datetime import datetime
from temporalio import activity
from workflows import RSSItem
from temporalio.service import RPCError
from temporalio.client import WorkflowExecutionStatus
import requests  # –¥–ª—è –±–æ–ª–µ–µ –≥–∏–±–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
import pytz  # –î–ª—è —Ä–∞–±–æ—Ç—ã —Å —á–∞—Å–æ–≤—ã–º–∏ –ø–æ—è—Å–∞–º–∏
from temporalio.client import Client

@activity.defn
async def check_feed_for_updates(feed_url: str, last_processed_guid: str = None) -> list:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç RSS-–ª–µ–Ω—Ç—É —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π 406 –∏ –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫"""
    try:
        # –ü–æ–ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ requests (–±–æ–ª–µ–µ –≥–∏–±–∫–æ)
        session = requests.Session()
        session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
              "(KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
            "Referer": "https://www.forexfactory.com/",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
        })

        try:
            response = session.get(feed_url, timeout=10)
            response.raise_for_status()
            feed_content = response.content
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 406:
                raise ValueError("–°–µ—Ä–≤–µ—Ä –æ—Ç–≤–µ—Ä–≥ –∑–∞–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π User-Agent –∏–ª–∏ URL.")
            raise ValueError(f"HTTP –æ—à–∏–±–∫–∞ {e.response.status_code}: {str(e)}")

        feed = feedparser.parse(feed_content)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π
        new_items = []
        is_new = True
        file = open("file.csv", "w")
        for entry in feed.entries:
            if is_new:
                for key in entry.keys():
                    file.write(f"{key}, ")
                file.write("\n")
                is_new = False
            try:
                guid = entry.get('id') or entry.get('guid') or entry.get('link', '')
                if last_processed_guid and guid == last_processed_guid:
                    break

                # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã –∏–∑ published
                pub_date_str = entry.get('published', '')
                if pub_date_str:
                    try:
                        # –§–æ—Ä–º–∞—Ç: 'Fri, 6 Jun 2025 08:49:00 +0300'
                        pub_date = datetime.strptime(pub_date_str, '%a, %d %b %Y %H:%M:%S %z')
                    except ValueError:
                        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç, –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç
                        pub_date = datetime.now(pytz.UTC)
                else:
                    pub_date = datetime.now(pytz.UTC)
                for key in entry.keys():
                    file.write(f"{entry[key]}, ")
                file.write("\n")
                new_items.append(RSSItem(
                    feed_url=feed_url,
                    title=entry.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'),
                    link=entry.get('link', ''),
                    description=entry.get('description', ''),
                    published_at=pub_date,
                    guid=guid
                ).to_dict())
            except Exception as e:
                activity.logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏: {str(e)}")
                continue
        file.close()

        return new_items[::-1] if new_items else []

    except Exception as e:
        activity.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {feed_url}: {str(e)}")
        return


@activity.defn
async def process_rss_item(feed_name: str, item_data: dict) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –∏–∑ RSS (–æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ –æ—á–µ—Ä–µ–¥—å)"""
    item = RSSItem.from_dict(item_data)
    # –ó–¥–µ—Å—å –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–º—É Temporal
        remote_client = await Client.connect("141.105.71.11:7233")

        # –ü–æ–ª—É—á–∞–µ–º —Ö—ç–Ω–¥–ª –æ–±—â–µ–≥–æ Workflow (ID —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
        workflow_handle = remote_client.get_workflow_handle("news-feed-workflow")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å workflow –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π —Å–∏–≥–Ω–∞–ª–∞
        try:
            desc = await workflow_handle.describe()
            if desc.status != WorkflowExecutionStatus.RUNNING:
                activity.logger.warning(
                    f"Workflow –Ω–µ –∑–∞–ø—É—â–µ–Ω (—Å—Ç–∞—Ç—É—Å: {desc.status}). "
                    f"–≠–ª–µ–º–µ–Ω—Ç –Ω–µ –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {item_data['guid']}"
                )
                return
        except Exception as e:
            activity.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ workflow: {str(e)}")
            raise

        send_data = {
            "id": item.guid,
            "timestamp": datetime.now().isoformat(),
            "data": item_data
        }

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç —á–µ—Ä–µ–∑ Signal —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–∫–∏
        try:
            await workflow_handle.signal(
                "news-feed-signal",
                send_data,
            )
            activity.logger.info(f"üì§ –£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —ç–ª–µ–º–µ–Ω—Ç: {item_data['guid']}")
        except RPCError as e:
            if "workflow execution already completed" in str(e):
                activity.logger.warning(
                    f"Workflow —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω. –≠–ª–µ–º–µ–Ω—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {item_data['guid']}"
                )
            else:
                raise

    except Exception as e:
        activity.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —ç–ª–µ–º–µ–Ω—Ç–∞ {item_data['guid']}: {str(e)}")
        return
