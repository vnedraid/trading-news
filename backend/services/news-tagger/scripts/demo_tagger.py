#!/usr/bin/env python3
"""
Demo script to show news-tagger functionality.
"""

import asyncio
import logging
import sys
import os
from datetime import datetime, timezone

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from models.news_item import NewsItem
from models.tagger_config import LLMConfig, TaggerConfig
from services.llm_service import LLMService


def setup_logging():
    """Configure logging for the demo."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # Set specific loggers to DEBUG for more detailed output
    logging.getLogger('services.llm_service').setLevel(logging.DEBUG)


async def demo_news_tagger():
    """Demonstrate news-tagger functionality with sample news."""
    print("üè∑Ô∏è  News Tagger Service - Demo")
    print("=" * 50)
    
    # Setup logging
    setup_logging()
    
    # Create sample news items (similar to what news-feeder would provide)
    sample_news = [
        NewsItem(
            title="–ú–æ—Å–±–∏—Ä–∂–∞ —Å 10 –∏—é–Ω—è –∑–∞–ø—É—Å—Ç–∏—Ç —Ç–æ—Ä–≥–∏ —Ñ—å—é—á–µ—Ä—Å–∞–º–∏ –Ω–∞ –∞–ø–µ–ª—å—Å–∏–Ω–æ–≤—ã–π —Å–æ–∫",
            url="https://www.kommersant.ru/doc/7777077",
            source="kommersant",
            content="–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –±–∏—Ä–∂–∞ –æ–±—ä—è–≤–∏–ª–∞ –æ –∑–∞–ø—É—Å–∫–µ —Ç–æ—Ä–≥–æ–≤ —Ñ—å—é—á–µ—Ä—Å–Ω—ã–º–∏ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞–º–∏ –Ω–∞ –∞–ø–µ–ª—å—Å–∏–Ω–æ–≤—ã–π —Å–æ–∫ —Å 10 –∏—é–Ω—è. –ù–æ–≤—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ–∑–≤–æ–ª–∏—Ç —É—á–∞—Å—Ç–Ω–∏–∫–∞–º —Ä—ã–Ω–∫–∞ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞—Ç—å —Ä–∏—Å–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é —Ü–µ–Ω –Ω–∞ —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—É—é –ø—Ä–æ–¥—É–∫—Ü–∏—é.",
            published_at=datetime.now(timezone.utc)
        ),
        NewsItem(
            title="Boeing –¥–æ–≥–æ–≤–æ—Ä–∏–ª—Å—è —Å –≤–ª–∞—Å—Ç—è–º–∏ –°–®–ê –æ –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏–∏ –ø—Ä–µ—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∑–∞ –∫—Ä—É—à–µ–Ω–∏—è 737 Max",
            url="https://www.kommersant.ru/doc/7776979",
            source="kommersant", 
            content="–ö–æ–º–ø–∞–Ω–∏—è Boeing –¥–æ—Å—Ç–∏–≥–ª–∞ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è —Å –ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ–º —é—Å—Ç–∏—Ü–∏–∏ –°–®–ê –æ –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏–∏ —É–≥–æ–ª–æ–≤–Ω–æ–≥–æ –ø—Ä–µ—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ —Å–≤—è–∑–∏ —Å –¥–≤—É–º—è –∞–≤–∏–∞–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞–º–∏ —Å–∞–º–æ–ª–µ—Ç–æ–≤ 737 Max. –°–æ–≥–ª–∞—à–µ–Ω–∏–µ –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –≤—ã–ø–ª–∞—Ç—É —à—Ç—Ä–∞—Ñ–∞ –∏ —É—Å–∏–ª–µ–Ω–∏–µ –º–µ—Ä –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.",
            published_at=datetime.now(timezone.utc)
        ),
        NewsItem(
            title="–≠–∫—Å–ø–æ—Ä—Ç —Ä–æ—Å—Å–∏–π—Å–∫–æ–π –ø—à–µ–Ω–∏—Ü—ã —Å–æ–∫—Ä–∞—Ç–∏—Ç—Å—è –Ω–∞ 20% –≤ —Ç–µ–∫—É—â–µ–º —Å–µ–∑–æ–Ω–µ",
            url="https://www.kommersant.ru/doc/7776695",
            source="kommersant",
            content="–ü–æ –¥–∞–Ω–Ω—ã–º –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤, —ç–∫—Å–ø–æ—Ä—Ç —Ä–æ—Å—Å–∏–π—Å–∫–æ–π –ø—à–µ–Ω–∏—Ü—ã –≤ —Ç–µ–∫—É—â–µ–º —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–º —Å–µ–∑–æ–Ω–µ –º–æ–∂–µ—Ç —Å–æ–∫—Ä–∞—Ç–∏—Ç—å—Å—è –Ω–∞ 20% –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –ø–µ—Ä–∏–æ–¥–æ–º –∏–∑-–∑–∞ –Ω–µ–±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—ã—Ö –ø–æ–≥–æ–¥–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π –∏ —Å–Ω–∏–∂–µ–Ω–∏—è —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏.",
            published_at=datetime.now(timezone.utc)
        )
    ]
    
    print(f"üì∞ Processing {len(sample_news)} sample news items")
    print()
    
    # Create LLM configuration (using mock/test settings)
    llm_config = LLMConfig(
        api_key="test-key-demo",  # This will fail API calls, but we can test the logic
        model="gpt-4",
        base_url="https://openrouter.ai/api/v1",
        max_tokens=150,
        temperature=0.3,
        timeout=30
    )
    
    # Create tagger configuration
    tagger_config = TaggerConfig(
        llm=llm_config,
        categories=[
            "finance", "trading", "markets", "commodities", "agriculture",
            "aviation", "corporate", "exports", "futures", "derivatives"
        ],
        min_confidence=0.7,
        max_tags=5
    )
    
    print(f"üîß LLM Model: {tagger_config.llm.model}")
    print(f"üè∑Ô∏è  Available categories: {len(tagger_config.categories)}")
    print(f"üìä Min confidence: {tagger_config.min_confidence}")
    print(f"üî¢ Max tags: {tagger_config.max_tags}")
    print()
    
    # Create LLM service
    service = LLMService(tagger_config)
    
    # Process each news item
    for i, news_item in enumerate(sample_news, 1):
        print(f"üìÑ Processing News Item {i}/{len(sample_news)}")
        print(f"   Title: {news_item.title}")
        print(f"   Source: {news_item.source}")
        print(f"   Content length: {len(news_item.content)} chars")
        print()
        
        try:
            # Test content extraction and validation
            content = service._extract_content(news_item)
            print(f"‚úÖ Content extracted successfully ({len(content)} chars)")
            
            # Test prompt building
            prompt = service._build_prompt(news_item)
            print(f"‚úÖ Prompt built successfully ({len(prompt)} chars)")
            print()
            
            # Note: We won't actually call the LLM API since we don't have valid credentials
            # But we can test the parsing logic with mock responses
            mock_response = {
                "tags": ["finance", "markets", "trading"],
                "confidence_scores": {
                    "finance": 0.95,
                    "markets": 0.87,
                    "trading": 0.72
                }
            }
            
            # Test response parsing
            import json
            mock_response_str = json.dumps(mock_response)
            result = service._parse_llm_response(mock_response_str, tagger_config.llm.model)
            print(f"‚úÖ Mock response parsed successfully")
            print(f"   Tags: {result.tags}")
            print(f"   Confidence scores: {result.confidence_scores}")
            
            # Test filtering
            filtered_result = service._apply_filters(result)
            print(f"‚úÖ Filtering applied successfully")
            print(f"   Filtered tags: {filtered_result.tags}")
            print(f"   Filtered scores: {filtered_result.confidence_scores}")
            print()
            
        except Exception as e:
            print(f"‚ùå Error processing news item: {e}")
            print()
    
    print("üéØ Demo completed successfully!")
    print("The News Tagger Service is ready to receive news from the feeder service.")


async def demo_integration_simulation():
    """Simulate integration between news-feeder and news-tagger."""
    print("\n" + "=" * 50)
    print("üîÑ Integration Simulation Demo")
    print("=" * 50)
    
    # This simulates what would happen when news-feeder sends news to news-tagger
    print("üì° Simulating news-feeder ‚Üí news-tagger integration...")
    print()
    
    # Sample news item from feeder
    news_from_feeder = NewsItem(
        title="Fix Price –æ–±–º–µ–Ω—è–µ—Ç –ì–î–† –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–æ–≥–æ —Ö–æ–ª–¥–∏–Ω–≥–∞ –Ω–∞ –∞–∫—Ü–∏–∏ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –∞–∫—Ç–∏–≤–∞",
        url="https://www.kommersant.ru/doc/7776920",
        source="news_feeder_rss",
        content="–ö–æ–º–ø–∞–Ω–∏—è Fix Price –ø–ª–∞–Ω–∏—Ä—É–µ—Ç –æ–±–º–µ–Ω—è—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–µ–ø–æ–∑–∏—Ç–∞—Ä–Ω—ã–µ —Ä–∞—Å–ø–∏—Å–∫–∏ (–ì–î–†) –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–æ–≥–æ —Ö–æ–ª–¥–∏–Ω–≥–∞ –Ω–∞ –∞–∫—Ü–∏–∏ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –∞–∫—Ç–∏–≤–∞. –û–ø–µ—Ä–∞—Ü–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ –ø–æ–≤—ã—à–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞–º–∏.",
        published_at=datetime.now(timezone.utc)
    )
    
    print(f"üì® Received news from feeder:")
    print(f"   Title: {news_from_feeder.title}")
    print(f"   Source: {news_from_feeder.source}")
    print(f"   URL: {news_from_feeder.url}")
    print()
    
    # Create tagger service
    llm_config = LLMConfig(
        api_key="test-integration-key",
        model="gpt-4"
    )
    
    tagger_config = TaggerConfig(
        llm=llm_config,
        categories=["finance", "corporate", "trading", "markets", "retail"],
        min_confidence=0.6,
        max_tags=3
    )
    
    service = LLMService(tagger_config)
    
    print("üè∑Ô∏è  Processing with tagger service...")
    
    # Validate content
    content = service._extract_content(news_from_feeder)
    if content.strip():
        print(f"‚úÖ Content validation passed ({len(content)} chars)")
        
        # Build prompt
        prompt = service._build_prompt(news_from_feeder)
        print(f"‚úÖ Prompt generated ({len(prompt)} chars)")
        
        # Simulate successful tagging (mock response)
        mock_tagged_result = {
            "tags": ["finance", "corporate", "retail"],
            "confidence_scores": {
                "finance": 0.92,
                "corporate": 0.85,
                "retail": 0.78
            }
        }
        
        print(f"‚úÖ Mock tagging completed:")
        print(f"   Generated tags: {mock_tagged_result['tags']}")
        print(f"   Confidence scores: {mock_tagged_result['confidence_scores']}")
        
        # Apply filtering
        import json
        result = service._parse_llm_response(json.dumps(mock_tagged_result), "gpt-4")
        filtered = service._apply_filters(result)
        
        print(f"‚úÖ Filtering applied (min_confidence={tagger_config.min_confidence}):")
        print(f"   Final tags: {filtered.tags}")
        print(f"   Final scores: {filtered.confidence_scores}")
        
        print()
        print("üì§ Tagged news would be sent to next workflow stage...")
        
    else:
        print("‚ùå Content validation failed - no meaningful content")
    
    print()
    print("‚úÖ Integration simulation completed!")


if __name__ == "__main__":
    print("Starting News Tagger Service Demo...")
    print()
    
    asyncio.run(demo_news_tagger())
    asyncio.run(demo_integration_simulation())
    
    print("\nüéâ All demos completed!")
    print("The News Tagger Service is ready for integration with the news-feeder service.")